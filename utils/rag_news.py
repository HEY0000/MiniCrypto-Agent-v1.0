# utils/rag_news.py

from langchain_community.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.docstore.document import Document
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
import os

NEWS_INDEX_PATH = "faiss_news_index"

def build_news_index(news_texts, save_path=NEWS_INDEX_PATH):
    """
    ë‰´ìŠ¤ ë³¸ë¬¸ ë˜ëŠ” íƒ€ì´í‹€+ì„¤ëª… ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not news_texts:
        raise ValueError("ğŸ” ë‰´ìŠ¤ ë‚´ìš©ì´ ë¹„ì–´ ìˆì–´ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    docs = [Document(page_content=t.strip()) for t in news_texts if t.strip()]
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(docs, embeddings)
    vectorstore.save_local(save_path)


def answer_news_query(user_query, index_path=NEWS_INDEX_PATH):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ FAISSì—ì„œ ìœ ì‚¬í•œ ë‰´ìŠ¤ ë²¡í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬ GPTë¡œ ì‘ë‹µí•©ë‹ˆë‹¤.
    """
    embeddings = OpenAIEmbeddings()

    # ì•ˆì „í•œ ë¡œë”© (ìì‹ ì´ ë§Œë“  ì¸ë±ìŠ¤ë¼ë©´ ê´œì°®ìŒ)
    vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)

    retriever = vectorstore.as_retriever(search_type="similarity", k=3)
    qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-4"),
    retriever=retriever,
    return_source_documents=False

)

    # ğŸ“¢ í”„ë¡¬í”„íŠ¸ ê°œì„  (ë‰´ìŠ¤ëŠ” ê³¼ê±° ì •ë³´ë¼ëŠ” ì  ì•ˆë‚´)
    prompt = f"""ì•„ë˜ëŠ” ê³¼ê±° ë‰´ìŠ¤ì…ë‹ˆë‹¤. ê·¸ë˜ë„ ê´€ë ¨ ë‚´ìš©ì´ ìˆë‹¤ë©´ ìš”ì•½í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”.
ì§ˆë¬¸: {user_query}
"""
    return qa_chain.run(prompt)
